# Insurance-Data-SQL-Analysis

Hi there. 

If you're viewing this, you're probably shopping around my portfolio. Maybe you're my future boss. Maybe you're a recruiter. Maybe you're a future client. Or maybe you're just a curious person. 

Whatever the case, it's lovely to meet you. 

## What is this?

Being a Data Journalist is part writer, part data visualiser, and part data-jack-of-all-trades. During 2024, I applied for a number of SQL data analysis roles. 

One company got back in touch via my profile on Otta[^1], and as part of the process sent me a take-home data analysis task, using real insurance data. 

[^1]: They got back three months after I applied via their website (job ad on LinkedIn). And they got in touch via my profile on Otta. I've got no idea if they simply ignored my first application, and spotted my Otta profile, or if they didn't action it, and my Otta profile rejigged their memory. Who knows. But that's the 2024 tech job market for you. 

The goal was to see if the candidate could join SQL datasets, and manipulate the data in SQL. 

While I didn't get the role, it was a fun process, and proved to myself that I have job ready SQL skills and can pass take home tests.[^2]

[^2]: The feedback they gave was that I should cite more of my previous experience in the interview. So it wasn't the data analysis. It was odd feedback though, because *there was never a chance to discuss my previous experience*, but it's feedback I've taken to heart. Regardless of the questions in an interview, I **always** share my previous experience at least once, even if it feels like a non-sequitur. But also – honestly, I appreciated the feedback. One big name UK company ghosted me on feedback even though I got to the third stage. I won't say who they are *cough* no I'm not saying who they are. I'm a professional. *cough*

Because of the deadline, and the time needed to do a write-up, I was unable to visualise the data using my usual data visualisation flair – they're dead simple charts I made in excel in the basic template. 

## What did you learn?

* The importance of checking for duplicates to test data quality
* Understanding the user flow when envisioning the data pipeline (this is a fancy way of saying thinking about how the data is actually made, a real person's experience, when thinking of what order to join the data)
* Using cohort analsys in SQL to draw conclusions in a tight timeframe.

## Where can I view the code?

Please note, this has been unchanged from when I submitted it to Urban Jungle. 

I used the magic `%sql` command in jupyter's ipython shell so that I could easily share my code, rather than creating a powerpoint presentation. I then exported it as HTML and sent it over. 

Times where I couldn't run the sql command in jupyter's shell, I included my SQL code as markdown.

**You can see my two part jupyter notebook solution here.**

**[Part 1](https://nbviewer.org/github/david-heasman00/Insurance-Data-Analysis/blob/main/Part%201%20%E2%80%93%20Cleaning%20and%20Joining%20the%20Data.ipynb)**
**[Part 2](https://nbviewer.org/github/david-heasman00/Insurance-Data-Analysis/blob/main/Part%202%20%E2%80%93%20Analysis%20and%20Answers.ipynb)**

## How can I speak to you?

Want to chat about a project, or a potential opportunity? I'm happy to connect [on LinkedIn](https://www.linkedin.com/in/davidheasman/). Include a brief note in your connection request about why you're reaching out. 

Till later. 

*David Heasman*\
*London, September 2024*

